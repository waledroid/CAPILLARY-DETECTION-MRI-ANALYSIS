# -*- coding: utf-8 -*-
"""ML Learning2Add.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pZOXP4mabnknDAfMcoLKy5-fsAKMwyKU

**RECONSTRUCTION AUTOENCODER**
"""

import torch
import torchvision
import torchvision.transforms as transforms
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F

from torchvision import datasets
from torch.utils.data import DataLoader
from torchvision.utils import save_image

import os
import matplotlib.pyplot as plt

# Are we using our GPU?
print("GPU available: {}".format(torch.cuda.is_available()))

"""Load Training and Test data, create our trasformations/Normalization, define our constants and make our data loaders"""

# constants

NUM_EPOCHS = 50
LEARNING_RATE = 0.001
BATCH_SIZE = 128

# image transformations and Normalization
#transform = transforms.Compose([transforms.ToTensor(),])

transform = transforms.Compose([transforms.ToTensor()])
mnist_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
data_loader = torch.utils.data.DataLoader(dataset=mnist_data, batch_size=64, shuffle=True)

trainset = torchvision.datasets.MNIST('mnist',
                                      train = True,
                                      download = True,
                                      transform = transform)

testset = torchvision.datasets.MNIST('mnist',
                                     train = False,
                                     download = True,
                                     transform = transform)

print(trainset.data.shape)
print(testset.data.shape)

"""Check Individual Sample of Data"""

# This is the first value in our dataset
print(trainset.data[0].shape)
print(trainset.data[0])

import cv2
import numpy as np
from matplotlib import pyplot as plt

# Define our imshow function
def imgshow(title="", image = None, size = 6):
    w, h = image.shape[0], image.shape[1]
    aspect_ratio = w/h
    plt.figure(figsize=(size * aspect_ratio,size))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title(title)
    plt.show()

# Convert image to a numpy array
image = trainset.data[0].numpy()
imgshow("MNIST Sample", image)

# Prepare train and test loader
trainloader = torch.utils.data.DataLoader(trainset,
                                           batch_size = BATCH_SIZE,
                                           shuffle = True,
                                           num_workers = 0)

testloader = torch.utils.data.DataLoader(testset,
                                          batch_size = BATCH_SIZE,
                                          shuffle = False,
                                          num_workers = 0)

"""# **1.**

Encoder:

The encoder will take an input image and gradually reduce its dimensionality while capturing important features. You can implement it as follows:
"""

class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(28 * 28, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 12),
            nn.ReLU(),
            nn.Linear(12, 2)  # Latent space
        )

    def forward(self, x):
        return self.encoder(x)

"""# **2.**

Decoder Options:

1. Exact Feature Mirror Model from the Encoder
"""

class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()
        self.decoder = nn.Sequential(
            nn.Linear(2, 12),
            nn.ReLU(),
            nn.Linear(12, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, 28 * 28),
            nn.Sigmoid()  # Sigmoid activation for image reconstruction
        )

    def forward(self, x):
        return self.decoder(x)

"""Decoder Options:
  
  2. transposed convolution layers, ReLU activations, and upsampling layers


"""

class DecoderTransposedConv(nn.Module):
    def __init__(self):
        super(DecoderTransposedConv, self).__init__()
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(2, 128, 7, stride=1),  # 2x2x128
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 4x4x64
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),  # 8x8x32
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, 4, stride=2, padding=1),  # 28x28x1
            nn.Sigmoid()  # Sigmoid activation for image reconstruction
        )

    def forward(self, x):
        return self.decoder(x)

decoder_transposed_conv = DecoderTransposedConv()

"""Decoder Options:
  
  3. Reshaping the Input Images to 64x64 and Using Upsampling

"""

class Decoder3(nn.Module):
    def __init__(self):
        super(Decoder3, self).__init__()
        self.fc3 = nn.Linear(2, 256)
        self.fc4 = nn.Linear(256, 64 * 16 * 16)  # Adjust for 64x64 size
        self.deconv1 = nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1)
        self.deconv2 = nn.ConvTranspose2d(32, 1, 4, stride=2, padding=1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc4(self.fc3(x))
        x = x.view(x.size(0), 64, 16, 16)  # Reshape
        x = self.deconv1(x)
        x = self.deconv2(x)
        x = self.sigmoid(x)
        return x

"""Activation Parameter used and why :

For the output layer of the decoder, **SIGMOID activation function** is used.

**self.sigmoid = nn.Sigmoid()**

Reason:  MNIST images have pixel values between 0 and 1. Sigmoid scales the output of the decoder to this range, making it suitable for image data

# **3.**
"""

class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = Encoder()
        self.decoder = Decoder()

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

# Example usage:
net = Autoencoder()

"""To make sure that the same model trained twice on the same data has similar performance and similar weights:

- Set random number generator seeds for NumPy, PyTorch to ensure      random processes (e.g., weight initialization, data shuffling) start from the same initial conditions in both training runs.

- Use same data split for training and evaluation. either by explicitly specifying the random seed for data splitting or by saving and reusing the same data split for both training runs.

- Use a logging system (e.g., TensorBoard or wandb) to record training conditions, hyperparameters, and model architecture.

- Save the trained model checkpoint, including weights, hyperparameters, and optimizer state, at the end of each training run. When evaluating the model again, load the same checkpoint. This guarantees the exact same model state.
"""

# @title
import random
import numpy as np

# Set seeds for reproducibility
seed = 42
torch.manual_seed(seed)
torch.cuda.manual_seed_all(seed)
np.random.seed(seed)
random.seed(seed)

"""Define our loss function and optimiser"""

#criterion = nn.MSELoss()
criterion = nn.BCELoss()
optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)

"""Train our Model

-Define our Training and Test functions
"""

# Firstly make some utility functions
def get_device():
    if torch.cuda.is_available():
        device = 'cuda:0'
    else:
        device = 'cpu'
    return device

def make_dir():
    image_dir = 'MNIST_Images'
    if not os.path.exists(image_dir):
        os.makedirs(image_dir)

def save_decoded_image(img, epoch):
    img = img.view(img.size(0), 1, 28, 28)
    save_image(img, './MNIST_Images/linear_ae_image{}.png'.format(epoch))

# Commented out IPython magic to ensure Python compatibility.
from sklearn.metrics import mean_squared_error

!pip install tensorboard
# %load_ext tensorboard
from torch.utils.tensorboard import SummaryWriter

# Initialize TensorBoard writer
writer = SummaryWriter()

# Training loop
def train(net, data_loader, NUM_EPOCHS):
    # train_loss = []
    for epoch in range(NUM_EPOCHS):
        net.train()
        train_loss = 0.0

        for data in trainloader:
            inputs, _ = data  # for both input and target
            inputs = inputs.view(inputs.size(0), -1).to(device) # Flatten images and move to the device

            # Forward pass
            outputs = net(inputs)
            loss = criterion(outputs, inputs)

            # Backpropagation and optimization
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        # Compute RMSE for the entire training dataset
        train_rmse = np.sqrt(train_loss / len(trainloader))


        # Validation phase ----------------------------------
        valid_loss = 0.0
        net.eval()  # Set the model to evaluation mode
        with torch.no_grad():
            for data in testloader:
                inputs, _ = data
                inputs = inputs.view(inputs.size(0), -1).to(device)
                outputs = net(inputs)
                loss = criterion(outputs, inputs)
                valid_loss += loss.item()

        # Compute RMSE for the entire validation dataset
        valid_rmse = np.sqrt(valid_loss / len(testloader))


        # Log or print the RMSE value for each epoch
        print(f'Epoch {epoch + 1}/{NUM_EPOCHS}, Training RMSE: {train_rmse:.4f}, Validation RMSE: {valid_rmse:.4f}')

        # Inside your training loop, log RMSE values
        writer.add_scalar('RMSE/Train', train_rmse, epoch)
        writer.add_scalar('RMSE/Validation', valid_rmse, epoch)


    # Save the final model checkpoint
    torch.save({
       'epoch': NUM_EPOCHS,
       'model_state_dict': net.state_dict(),
       'optimizer_state_dict': optimizer.state_dict(),
       # ... other necessary information
    }, f'model_checkpoint_epoch{NUM_EPOCHS}.pth')

# get the computation device
device = get_device()
print(device)

# load the neural network onto the device
net.to(device)

make_dir()

# train the network
train(net, trainloader, NUM_EPOCHS)

# Close the writer after training is complete
writer.close()

# Testing the autoencoder
def evaluate_model(model, test_loader, device):
    model.eval()  # Set the model to evaluation mode
    val_loss = 0.0

    with torch.no_grad():
        # Fetch a batch of test images
        test_images, _ = next(iter(test_loader))
        test_images = test_images.view(test_images.size(0), -1).to(device)

        # Forward pass through the model to get reconstructed images
        reconstructed = model(test_images)
        loss = criterion(reconstructed, test_images)
        val_loss += loss.item()

        # Move reconstructed images and test images back to CPU for visualization
        reconstructed = reconstructed.cpu().numpy()
        test_images = test_images.cpu().numpy()

    # Compute RMSE for the entire validation dataset
    val_rmse = np.sqrt(val_loss / len(testloader))


    return test_images, reconstructed


test_images, reconstructed = evaluate_model(net, testloader, device)


# Display original and reconstructed images
n = 10  # Number of images to display
plt.figure(figsize=(20, 4))
for i in range(n):
    # Original Images
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(test_images[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Reconstructed Images
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(reconstructed[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir=runs

"""# **Part III**
- Learning to Perform Addition from Images


"""

# function to create dataset with new samples for the addition of numbers
def transform_data_add( x_train , y_train , img_size = [32 ,32]) :
  number_list = [0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9]
  value_add_list = []